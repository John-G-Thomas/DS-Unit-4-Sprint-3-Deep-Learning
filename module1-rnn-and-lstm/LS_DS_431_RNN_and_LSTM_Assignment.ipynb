{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
    "\n",
    "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
    "\n",
    "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
    "\n",
    "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
    "\n",
    "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
    "\n",
    "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
    "\n",
    "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
    "\n",
    "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-15T18:18:20.453Z",
     "iopub.status.busy": "2020-06-15T18:18:20.442Z",
     "iopub.status.idle": "2020-06-15T18:18:20.513Z",
     "shell.execute_reply": "2020-06-15T18:18:20.523Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-15T18:25:49.781Z",
     "iopub.status.busy": "2020-06-15T18:25:49.778Z",
     "iopub.status.idle": "2020-06-15T18:25:51.467Z",
     "shell.execute_reply": "2020-06-15T18:25:51.469Z"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://www.gutenberg.org/files/100/100-0.txt\"\n",
    "\n",
    "r = requests.get(url)\n",
    "r.encoding = r.apparent_encoding\n",
    "data = r.text\n",
    "data = data.split('\\r\\n')\n",
    "toc = [l.strip() for l in data[44:130:2]]\n",
    "# Skip the Table of Contents\n",
    "data = data[135:]\n",
    "\n",
    "# Fixing Titles\n",
    "toc[9] = 'THE LIFE OF KING HENRY V'\n",
    "toc[18] = 'MACBETH'\n",
    "toc[24] = 'OTHELLO, THE MOOR OF VENICE'\n",
    "toc[34] = 'TWELFTH NIGHT: OR, WHAT YOU WILL'\n",
    "\n",
    "locations = {id_:{'title':title, 'start':-99} for id_,title in enumerate(toc)}\n",
    "\n",
    "# Start \n",
    "for e,i in enumerate(data):\n",
    "    for t,title in enumerate(toc):\n",
    "        if title in i:\n",
    "            locations[t].update({'start':e})\n",
    "\n",
    "df_toc = pd.DataFrame.from_dict(locations, orient='index')\n",
    "df_toc['end'] = df_toc['start'].shift(-1).apply(lambda x: x-1)\n",
    "df_toc.loc[42, 'end'] = len(data)\n",
    "df_toc['end'] = df_toc['end'].astype('int')\n",
    "\n",
    "df_toc['text'] = df_toc.apply(lambda x: '\\r\\n'.join(data[ x['start'] : int(x['end']) ]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From fairest creatures we desire increase,'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169308"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-15T18:26:12.637Z",
     "iopub.status.busy": "2020-06-15T18:26:12.630Z",
     "iopub.status.idle": "2020-06-15T18:26:12.643Z",
     "shell.execute_reply": "2020-06-15T18:26:12.647Z"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>THE TRAGEDY OF ANTONY AND CLEOPATRA</td>\n",
       "      <td>-99</td>\n",
       "      <td>14379</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AS YOU LIKE IT</td>\n",
       "      <td>14380</td>\n",
       "      <td>17171</td>\n",
       "      <td>AS YOU LIKE IT\\r\\n\\r\\n\\r\\nDRAMATIS PERSONAE.\\r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>THE COMEDY OF ERRORS</td>\n",
       "      <td>17172</td>\n",
       "      <td>20372</td>\n",
       "      <td>THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THE TRAGEDY OF CORIOLANUS</td>\n",
       "      <td>20373</td>\n",
       "      <td>30346</td>\n",
       "      <td>THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CYMBELINE</td>\n",
       "      <td>30347</td>\n",
       "      <td>30364</td>\n",
       "      <td>CYMBELINE.\\r\\nLaud we the gods;\\r\\nAnd let our...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>THE TRAGEDY OF HAMLET, PRINCE OF DENMARK</td>\n",
       "      <td>30365</td>\n",
       "      <td>37051</td>\n",
       "      <td>THE TRAGEDY OF HAMLET, PRINCE OF DENMARK\\r\\n\\r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>THE FIRST PART OF KING HENRY THE FOURTH</td>\n",
       "      <td>37052</td>\n",
       "      <td>41767</td>\n",
       "      <td>THE FIRST PART OF KING HENRY THE FOURTH\\r\\n\\r\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>THE SECOND PART OF KING HENRY THE FOURTH</td>\n",
       "      <td>41768</td>\n",
       "      <td>-100</td>\n",
       "      <td>THE SECOND PART OF KING HENRY THE FOURTH\\r\\n\\r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>THE LIFE OF KING HENRY THE FIFTH</td>\n",
       "      <td>-99</td>\n",
       "      <td>45176</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>THE LIFE OF KING HENRY V</td>\n",
       "      <td>45177</td>\n",
       "      <td>53383</td>\n",
       "      <td>THE LIFE OF KING HENRY V\\r\\n\\r\\n\\r\\n\\r\\nConten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>THE SECOND PART OF KING HENRY THE SIXTH</td>\n",
       "      <td>53384</td>\n",
       "      <td>56871</td>\n",
       "      <td>THE SECOND PART OF KING HENRY THE SIXTH\\r\\n\\r\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>THE THIRD PART OF KING HENRY THE SIXTH</td>\n",
       "      <td>56872</td>\n",
       "      <td>60257</td>\n",
       "      <td>THE THIRD PART OF KING HENRY THE SIXTH\\r\\n\\r\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KING HENRY THE EIGHTH</td>\n",
       "      <td>60258</td>\n",
       "      <td>66710</td>\n",
       "      <td>KING HENRY THE EIGHTH\\r\\n\\r\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KING JOHN</td>\n",
       "      <td>66711</td>\n",
       "      <td>66783</td>\n",
       "      <td>KING JOHN. O cousin, thou art come to set mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>THE TRAGEDY OF JULIUS CAESAR</td>\n",
       "      <td>66784</td>\n",
       "      <td>71427</td>\n",
       "      <td>THE TRAGEDY OF JULIUS CAESAR\\r\\n\\r\\n\\r\\n\\r\\nCo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>THE TRAGEDY OF KING LEAR</td>\n",
       "      <td>71428</td>\n",
       "      <td>77463</td>\n",
       "      <td>THE TRAGEDY OF KING LEAR\\r\\n\\r\\n\\r\\n\\r\\nConten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LOVE’S LABOUR’S LOST</td>\n",
       "      <td>77464</td>\n",
       "      <td>-100</td>\n",
       "      <td>LOVE’S LABOUR’S LOST\\r\\n\\r\\nDramatis Personae....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>THE TRAGEDY OF MACBETH</td>\n",
       "      <td>-99</td>\n",
       "      <td>84427</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MACBETH</td>\n",
       "      <td>84428</td>\n",
       "      <td>87527</td>\n",
       "      <td>MACBETH.\\r\\nI will not yield,\\r\\nTo kiss the g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>THE MERCHANT OF VENICE</td>\n",
       "      <td>87528</td>\n",
       "      <td>91695</td>\n",
       "      <td>THE MERCHANT OF VENICE\\r\\n\\r\\n\\r\\n\\r\\nContents...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       title  start    end  \\\n",
       "0        THE TRAGEDY OF ANTONY AND CLEOPATRA    -99  14379   \n",
       "1                             AS YOU LIKE IT  14380  17171   \n",
       "2                       THE COMEDY OF ERRORS  17172  20372   \n",
       "3                  THE TRAGEDY OF CORIOLANUS  20373  30346   \n",
       "4                                  CYMBELINE  30347  30364   \n",
       "5   THE TRAGEDY OF HAMLET, PRINCE OF DENMARK  30365  37051   \n",
       "6    THE FIRST PART OF KING HENRY THE FOURTH  37052  41767   \n",
       "7   THE SECOND PART OF KING HENRY THE FOURTH  41768   -100   \n",
       "8           THE LIFE OF KING HENRY THE FIFTH    -99  45176   \n",
       "9                   THE LIFE OF KING HENRY V  45177  53383   \n",
       "10   THE SECOND PART OF KING HENRY THE SIXTH  53384  56871   \n",
       "11    THE THIRD PART OF KING HENRY THE SIXTH  56872  60257   \n",
       "12                     KING HENRY THE EIGHTH  60258  66710   \n",
       "13                                 KING JOHN  66711  66783   \n",
       "14              THE TRAGEDY OF JULIUS CAESAR  66784  71427   \n",
       "15                  THE TRAGEDY OF KING LEAR  71428  77463   \n",
       "16                      LOVE’S LABOUR’S LOST  77464   -100   \n",
       "17                    THE TRAGEDY OF MACBETH    -99  84427   \n",
       "18                                   MACBETH  84428  87527   \n",
       "19                    THE MERCHANT OF VENICE  87528  91695   \n",
       "\n",
       "                                                 text  \n",
       "0                                                      \n",
       "1   AS YOU LIKE IT\\r\\n\\r\\n\\r\\nDRAMATIS PERSONAE.\\r...  \n",
       "2   THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...  \n",
       "3   THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...  \n",
       "4   CYMBELINE.\\r\\nLaud we the gods;\\r\\nAnd let our...  \n",
       "5   THE TRAGEDY OF HAMLET, PRINCE OF DENMARK\\r\\n\\r...  \n",
       "6   THE FIRST PART OF KING HENRY THE FOURTH\\r\\n\\r\\...  \n",
       "7   THE SECOND PART OF KING HENRY THE FOURTH\\r\\n\\r...  \n",
       "8                                                      \n",
       "9   THE LIFE OF KING HENRY V\\r\\n\\r\\n\\r\\n\\r\\nConten...  \n",
       "10  THE SECOND PART OF KING HENRY THE SIXTH\\r\\n\\r\\...  \n",
       "11  THE THIRD PART OF KING HENRY THE SIXTH\\r\\n\\r\\n...  \n",
       "12                   KING HENRY THE EIGHTH\\r\\n\\r\\n...  \n",
       "13    KING JOHN. O cousin, thou art come to set mi...  \n",
       "14  THE TRAGEDY OF JULIUS CAESAR\\r\\n\\r\\n\\r\\n\\r\\nCo...  \n",
       "15  THE TRAGEDY OF KING LEAR\\r\\n\\r\\n\\r\\n\\r\\nConten...  \n",
       "16  LOVE’S LABOUR’S LOST\\r\\n\\r\\nDramatis Personae....  \n",
       "17                                                     \n",
       "18  MACBETH.\\r\\nI will not yield,\\r\\nTo kiss the g...  \n",
       "19  THE MERCHANT OF VENICE\\r\\n\\r\\n\\r\\n\\r\\nContents...  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shakespeare Data Parsed by Play\n",
    "df_toc.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AS YOU LIKE IT\\r\\n\\r\\n\\r\\nDRAMATIS PERSONAE.\\r\\n\\r\\n  DUKE, living in exile\\r\\n  FREDERICK, his brother, and usu'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loc to see what text looks like\n",
    "df_toc['text'][1][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169308"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'That thereby beauty’s rose might never die,'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LambdaCallback, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>THE TRAGEDY OF JULIUS CAESAR</td>\n",
       "      <td>66784</td>\n",
       "      <td>71427</td>\n",
       "      <td>THE TRAGEDY OF JULIUS CAESAR\\r\\n\\r\\n\\r\\n\\r\\nCo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title  start    end  \\\n",
       "14  THE TRAGEDY OF JULIUS CAESAR  66784  71427   \n",
       "\n",
       "                                                 text  \n",
       "14  THE TRAGEDY OF JULIUS CAESAR\\r\\n\\r\\n\\r\\n\\r\\nCo...  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find Hamlet\n",
    "df_toc[df_toc['title'].str.match('THE TRAGEDY OF JULIUS CAESAR')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'THE TRAGEDY OF JULIUS CAESAR', 'start': 66784}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121284"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAGEDY = df_toc['text'][14]\n",
    "len(TRAGEDY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our corpus contains 72 unique characters.\n"
     ]
    }
   ],
   "source": [
    "chars = list(set(TRAGEDY))\n",
    "\n",
    "char_int = {c:i for i,c in enumerate(chars)}\n",
    "int_char = {i:c for i,c in enumerate(chars)}\n",
    "\n",
    "print(f\"Our corpus contains {len(chars)} unique characters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences: 121134\n"
     ]
    }
   ],
   "source": [
    "# Create the Sequence Data\n",
    "\n",
    "maxlen = 150\n",
    "step = 1\n",
    "\n",
    "encoded = [char_int[c] for c in TRAGEDY]\n",
    "\n",
    "sequences = [] # Each element is 40 characters long\n",
    "next_chars = [] # One element for each sequence\n",
    "\n",
    "for i in range(0, len(encoded) - maxlen, step):\n",
    "    sequences.append(encoded[i : i + maxlen])\n",
    "    next_chars.append(encoded[i + maxlen])\n",
    "    \n",
    "print('sequences:', len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify x & y\n",
    "\n",
    "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sequence in enumerate(sequences):\n",
    "    for t, char in enumerate(sequence):\n",
    "        x[i,t,char] = 1\n",
    "        \n",
    "    y[i, next_chars[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((121134, 150, 72), (121134, 72))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model: a single LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(maxlen, len(chars)), dropout=0.2))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='nadam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 256)               336896    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 72)                18504     \n",
      "=================================================================\n",
      "Total params: 355,400\n",
      "Trainable params: 355,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / 1\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    \n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "    \n",
    "    start_index = random.randint(0, len(TRAGEDY) - maxlen - 1)\n",
    "    \n",
    "    generated = ''\n",
    "    \n",
    "    sentence = TRAGEDY[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    \n",
    "    print('----- Generating with seed: ----- \\n')\n",
    "    sys.stdout.write(generated)\n",
    "    \n",
    "    print('\\n\\n\\n-----New text: -----')\n",
    "\n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_int[char]] = 1\n",
    "            \n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds)\n",
    "        next_char = int_char[next_index]\n",
    "        \n",
    "        sentence = sentence[1:] + next_char\n",
    "        \n",
    "        sys.stdout.write(next_char)\n",
    "    print()\n",
    "    sys.stdout.flush()\n",
    "    print('\\n\\n')\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3029/3029 [==============================] - ETA: 0s - loss: 2.3504\n",
      "----- Generating text after Epoch: 0\n",
      "----- Generating with seed: ----- \n",
      "\n",
      "’d.\n",
      "\n",
      "ARTEMIDORUS.\n",
      "Delay not, Caesar. Read it instantly.\n",
      "\n",
      "CAESAR.\n",
      "What, is the fellow mad?\n",
      "\n",
      "PUBLIUS.\n",
      "Sirrah, give place.\n",
      "\n",
      "CASSIUS.\n",
      "What, ur\n",
      "\n",
      "\n",
      "-----New text: -----\n",
      "enysu s oond supsure.\n",
      "\n",
      "F[_tureteas. I\n",
      "Hellyttes Than’deUtiBr ene ait yst And no honm\n",
      "\n",
      "inRSinkerlltsh anChese lestme he yould\n",
      "As Irouto the bush’l the Cassar.\n",
      "Eobeyou mellt, [ ous on wirl on Loubou mom nom enaesprt\n",
      "Asd sete’s asfon ne you salh this so?h\n",
      "\n",
      "BRUTUS.\n",
      "Deloursnowtert on,\n",
      "Cabear sole ere sech ut you the hirelos refshat amd CBoCpA.\n",
      "Imchas tter tun shi hallut ansthe?\n",
      "O whitear. \n",
      "\n",
      "\n",
      "\n",
      "3029/3029 [==============================] - 917s 303ms/step - loss: 2.3504 - val_loss: 2.0237\n",
      "Epoch 2/10\n",
      "3029/3029 [==============================] - ETA: 0s - loss: 2.0382\n",
      "----- Generating text after Epoch: 1\n",
      "----- Generating with seed: ----- \n",
      "\n",
      "ed and valiant soldier.\n",
      "\n",
      "ANTONY.\n",
      "So is my horse, Octavius; and for that\n",
      "I do appoint him store of provender.\n",
      "It is a creature that I teach to fig\n",
      "\n",
      "\n",
      "-----New text: -----\n",
      "se Caesar.\n",
      "Anther yrurist alo lidk. of me prasiee sbands;\n",
      "M lhes Hit nrth purs of Diat; burn shick  not,\n",
      "But in nnor; au shay e wrech.\n",
      "\n",
      "BRUTUS.\n",
      "Whth met ver, horgl\n",
      "I hover I ntan willod a \n",
      "Ant thire are ther, ast; beand, henor wis; Romelw\n",
      "I ho choed urubllt sfond, thenlor, blood, Brutus,\n",
      "Leerundryss w ll cond, did she, Caesar,\n",
      "And Lurutus stall and withrmur sthene \n",
      "BRUTUS.\n",
      "I dives, ong\n",
      "\n",
      "\n",
      "\n",
      "3029/3029 [==============================] - 925s 305ms/step - loss: 2.0382 - val_loss: 1.8537\n",
      "Epoch 3/10\n",
      "3029/3029 [==============================] - ETA: 0s - loss: 1.9080\n",
      "----- Generating text after Epoch: 2\n",
      "----- Generating with seed: ----- \n",
      "\n",
      "do\n",
      "Is to himself; take thought and die for Caesar.\n",
      "And that were much he should; for he is given\n",
      "To sports, to wildness, and much company.\n",
      "\n",
      "TREBO\n",
      "\n",
      "\n",
      "-----New text: -----\n",
      "NI.\n",
      "Your whice your vavveed this; the well drow, s keos come.\n",
      "Iutil, recely the shall thaneyou doncab-silzsoth’d,\n",
      "A dis sutusur morrcethers? hash irTrefenestaf.\n",
      "Pooply ou his evele sfort:\n",
      "Whet I crive theyeIfoP oft.\n",
      "\n",
      "PORTIA.\n",
      "Mety lou a lovenn laverer till to wick sim,\n",
      "The prradspoosesg tils in be ame,\n",
      "Andea droweroncerhove wile threyprackey.\n",
      "\n",
      "CASSIUS.\n",
      "Ar Cossius, gote loiedshis dourde\n",
      "\n",
      "\n",
      "\n",
      "3029/3029 [==============================] - 937s 309ms/step - loss: 1.9080 - val_loss: 1.7547\n",
      "Epoch 4/10\n",
      "3029/3029 [==============================] - ETA: 0s - loss: 1.8267\n",
      "----- Generating text after Epoch: 3\n",
      "----- Generating with seed: ----- \n",
      "\n",
      "isten well.\n",
      "I heard a bustling rumour, like a fray,\n",
      "And the wind brings it from the Capitol.\n",
      "\n",
      "LUCIUS.\n",
      "Sooth, madam, I hear nothing.\n",
      "\n",
      " Enter the\n",
      "\n",
      "\n",
      "-----New text: -----\n",
      " Dettel.\n",
      "\n",
      "CASCA.\n",
      "Artant, fire your havd your our henen., mank boom ryme man Antony,\n",
      "And po, s man or ohCde trustses.\n",
      "Shou\n",
      " well much, kwond vere ine s ofsBrut,\n",
      "And is and that, an it in madse ho.\n",
      "\n",
      "CASCA.\n",
      "If thal I shall me, gove be not his hand\n",
      "Thm, a this ang of teld oblion.\n",
      "Sman hack hat foala thiu Calpir thou oftedphides,\n",
      "And frean him, is the patcer londs and\n",
      "Camer graedds:\n",
      "_Are\n",
      "\n",
      "\n",
      "\n",
      "3029/3029 [==============================] - 922s 304ms/step - loss: 1.8267 - val_loss: 1.6917\n",
      "Epoch 5/10\n",
      "3029/3029 [==============================] - ETA: 0s - loss: 1.7558\n",
      "----- Generating text after Epoch: 4\n",
      "----- Generating with seed: ----- \n",
      "\n",
      "e.\n",
      "I do entreat you, not a man depart,\n",
      "Save I alone, till Antony have spoke.\n",
      "\n",
      " [_Exit._]\n",
      "\n",
      "FIRST CITIZEN.\n",
      "Stay, ho! and let us hear Mark Antony.\n",
      "\n",
      "\n",
      "-----New text: -----\n",
      "\n",
      "\n",
      "THIRD CITIZEN.\n",
      "Way, a dise? Petime, afe kngr sich him.\n",
      "\n",
      "CASSIUS.\n",
      "What, you as or. Markh.r\n",
      "\n",
      "SEnOND CITIZEN.\n",
      "Wet meshartem Brutus.\n",
      "Bct,\n",
      "onoy all bis al stare turt dighont godl the wall, Mark offaze reghts.\n",
      "Of Brutus. Yen you hame. I he yan, non thus?\n",
      "\n",
      "BRUTUS.\n",
      "Ayons thoubhims is him. I gay him a fill\n",
      "A hove Caesar’s mecpro? Caedar the evorsor;\n",
      "The all the will; and what suide to bef\n",
      "\n",
      "\n",
      "\n",
      "3029/3029 [==============================] - 937s 309ms/step - loss: 1.7558 - val_loss: 1.6551\n",
      "Epoch 6/10\n",
      "3029/3029 [==============================] - ETA: 0s - loss: 1.7035\n",
      "----- Generating text after Epoch: 5\n",
      "----- Generating with seed: ----- \n",
      "\n",
      "l forth. The things that threaten’d me\n",
      "Ne’er look’d but on my back; when they shall see\n",
      "The face of Caesar, they are vanished.\n",
      "\n",
      "CALPHURNIA.\n",
      "Caesa\n",
      "\n",
      "\n",
      "-----New text: -----\n",
      "r—\n",
      "\n",
      "CESSIUS.\n",
      "No, Cisiza, that Goom, you aaptere, I would: let um nothous yours leademome,\n",
      "Like it musaret!\n",
      "\n",
      "TIRDT CITIZEN.\n",
      "Then foll me\n",
      "I\n",
      "CASSIUS.\n",
      "Morehy thick Antony, I do to fancd. Go k di\n",
      " as but me bust Caesar cantles, beteny\n",
      "Hobefare nim of hear have made\n",
      "Then to dEart and the youge on so?\n",
      "\n",
      "CASSIUS.\n",
      "The poith alk: yourfides ahey me shall wooke\n",
      "To we vancy, chango he sonmind no\n",
      "\n",
      "\n",
      "\n",
      "3029/3029 [==============================] - 931s 307ms/step - loss: 1.7035 - val_loss: 1.6160\n",
      "Epoch 7/10\n",
      "3029/3029 [==============================] - ETA: 0s - loss: 1.6550\n",
      "----- Generating text after Epoch: 6\n",
      "----- Generating with seed: ----- \n",
      "\n",
      "nators rise.\n",
      "\n",
      "POPILIUS.\n",
      "I wish your enterprise today may thrive.\n",
      "\n",
      "CASSIUS.\n",
      "What enterprise, Popilius?\n",
      "\n",
      "POPILIUS.\n",
      "Fare you well.\n",
      "\n",
      " [_Advance\n",
      "\n",
      "\n",
      "-----New text: -----\n",
      "] Lutirius._]\n",
      "\n",
      "SARTANA.\n",
      "Pardme you?\n",
      "\n",
      "CINNA.\n",
      "Weece, MarkIA the Cepitol, betn ant.\n",
      "\n",
      "BRUTUS.\n",
      "Trerpom’d Carsa. Bearius wrent tae; the bedls to arydesasedU\n",
      "Ay follome! he what croms of ers,\n",
      "Let no bost then heand.\n",
      "\n",
      "LUCILIUS.\n",
      "If I have love, me wannod us then.\n",
      "\n",
      "SECNND CITIZEN.\n",
      "Heteld, and Pubrius!\n",
      "\n",
      "CAESAR.\n",
      "He shent, and here, lit in cowars, Thin that; out is their broons,\n",
      "Which the \n",
      "\n",
      "\n",
      "\n",
      "3029/3029 [==============================] - 910s 300ms/step - loss: 1.6550 - val_loss: 1.5906\n",
      "Epoch 8/10\n",
      "3029/3029 [==============================] - ETA: 0s - loss: 1.6141\n",
      "----- Generating text after Epoch: 7\n",
      "----- Generating with seed: ----- \n",
      "\n",
      " within their wills,\n",
      "Bequeathing it as a rich legacy\n",
      "Unto their issue.\n",
      "\n",
      "FOURTH CITIZEN.\n",
      "We’ll hear the will. Read it, Mark Antony.\n",
      "\n",
      "CITIZENS.\n",
      "\n",
      "\n",
      "\n",
      "-----New text: -----\n",
      "Let y er hearthy spilk? Selu are you let me; spebcctite,.\n",
      "Whew hats a ese bring mi, Are I that you say,\n",
      "But ne rabne in Antony speak, was,\n",
      "Fill not, und seer pressice’s tre ring.\n",
      "Let se bling by seer bad show so mubtered.\n",
      "\n",
      "BRUTUS.\n",
      "Ponalius Brutus, Caesar Antony,\n",
      "Wh’t sot no speectler, I whallThe pealustor’d,\n",
      "Indisg to breass bonged out, go, \n",
      ", Leaid of such all\n",
      "That bovph his figlte to sp\n",
      "\n",
      "\n",
      "\n",
      "3029/3029 [==============================] - 892s 294ms/step - loss: 1.6141 - val_loss: 1.5759\n",
      "Epoch 9/10\n",
      "3029/3029 [==============================] - ETA: 0s - loss: 1.5809\n",
      "----- Generating text after Epoch: 8\n",
      "----- Generating with seed: ----- \n",
      "\n",
      "IUS.\n",
      "Why, man, he doth bestride the narrow world\n",
      "Like a Colossus, and we petty men\n",
      "Walk under his huge legs, and peep about\n",
      "To find ourselves dish\n",
      "\n",
      "\n",
      "-----New text: -----\n",
      "onger thesl\n",
      "For the bondsaff to thy forthus!\n",
      "That I erongs.\n",
      "\n",
      "CASSAUS.\n",
      "What you dests-rinturh todigemy press’ve hor;.\n",
      "Poopping as that you may, say anCe, forr,\n",
      "Andward this our men, aid,\n",
      "O inglictfulf, nor no neved thie,\n",
      "Hove though hos meacons at if you god,\n",
      "Those wispous reasens orded. Andowhre’d\n",
      "Your knavl’d, ald stemn to to whrngk and Lusirs lest fite you.\n",
      "\n",
      "CASSIUS.\n",
      "Have night, in\n",
      "\n",
      "\n",
      "\n",
      "3029/3029 [==============================] - 904s 298ms/step - loss: 1.5809 - val_loss: 1.5545\n",
      "Epoch 10/10\n",
      "3029/3029 [==============================] - ETA: 0s - loss: 1.5537\n",
      "----- Generating text after Epoch: 9\n",
      "----- Generating with seed: ----- \n",
      "\n",
      "\n",
      "Here is the will, and under Caesar’s seal.\n",
      "To every Roman citizen he gives,\n",
      "To every several man, seventy-five drachmas.\n",
      "\n",
      "SECOND CITIZEN.\n",
      "Most n\n",
      "\n",
      "\n",
      "-----New text: -----\n",
      "oble men! But you trare the mudger.\n",
      "\n",
      "CAESAR.\n",
      "Brutus, hesrsw and doke mys  our een,\n",
      "Indeke chathers? where out thith the soude\n",
      "That I fod a dudss buroen:\n",
      "Eut ill; and, Caspius’d. lovv’d at you\n",
      "\n",
      " [_Exit Lugilius._]\n",
      "\n",
      "Fiuce, wise crown you are with a sive taik.\n",
      "\n",
      "SCENE IV. Tee ther thing hear wis night in. and where prey orme couth\n",
      "Sicks and a terer it the thuwt.\n",
      "\n",
      " not Y. ] virtuno\n",
      "\n",
      "\n",
      "\n",
      "3029/3029 [==============================] - 916s 302ms/step - loss: 1.5537 - val_loss: 1.5593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19a1f44b400>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=32,\n",
    "          validation_split=.2,\n",
    "          epochs=10,\n",
    "          callbacks=[print_callback, \n",
    "                     #EarlyStopping(min_delta=.02, monitor='val_loss', patience=10),\n",
    "                     tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 5188), started 3:54:23 ago. (Use '!kill 5188' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-30626490b7645521\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-30626490b7645521\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-134-981b0190cb3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\r\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mchars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mchar_int\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "text = '\\r\\n'.join(text)\n",
    "\n",
    "chars = list(set(text))\n",
    "\n",
    "char_int = {c:i for i,c in enumerate(chars)}\n",
    "int_char = {i:c for i,c in enumerate(chars)}\n",
    "\n",
    "print(f\"Our corpus contains {len(chars)} unique characters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 40\n",
    "step = 5\n",
    "\n",
    "encoded = [char_int[c] for c in text]\n",
    "\n",
    "sequences = [] # Each element is 40 chars long\n",
    "next_char = [] # One element for each sequence\n",
    "\n",
    "for i in range(0, len(encoded) - maxlen, step):\n",
    "    \n",
    "    sequences.append(encoded[i : i + maxlen])\n",
    "    next_char.append(encoded[i + maxlen])\n",
    "    \n",
    "print('sequences: ', len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences),len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sequence in enumerate(sequences):\n",
    "    for t, char in enumerate(sequence):\n",
    "        x[i,t,char] = 1\n",
    "    y[i, next_char[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='adam'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Nadam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / 1\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    \n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "    \n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    \n",
    "    generated = ''\n",
    "    \n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    \n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "    \n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_int[char]] = 1\n",
    "            \n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds)\n",
    "        next_char = int_char[next_index]\n",
    "        \n",
    "        sentence = sentence[1:] + next_char\n",
    "        \n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()\n",
    "\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=50,\n",
    "          callbacks=[print_callback],\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zE4a4O7Bp5x1"
   },
   "source": [
    "# Resources and Stretch Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "## Stretch goals:\n",
    "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
    "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
    "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
    "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
    "- Run on bigger, better data\n",
    "\n",
    "## Resources:\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
    "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
    "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
    "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
    "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "0.23.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
